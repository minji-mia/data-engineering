## Overview
This course teaches me how to build pipelines to import data kept in common storage formats. 
I used pandas, a major Python library for analytics, to get data from a variety of sources, from spreadsheets of survey responses, to a database of public service requests, 
to an API for a popular review site. Along the way, I learned how to fine-tune imports to get only what you need and to address issues like incorrect data types.
Finally, I assembled a custom dataset from a mix of sources.

### 1. Importing Data from Flat Files
Practice using pandas to get just the data I want from flat files, learn how to wrangle data types and handle errors, and look into some U.S. tax data along the way.

### 2. Importing Data From Excel Files
Automate data imports from that staple of office life, Excel files. 
Import part or all of a workbook and ensure boolean and datetime data are properly loaded, all while learning about how other people are learning to code.

### 3. Importing Data from Databases
Combine pandas with the powers of SQL to find out just how many problems New Yorkers have with their housing. 
This chapter features introductory SQL topics like WHERE clauses, aggregate functions, and basic joins.

### 4. Importing JSON Data and Working with APIs
Learn how to work with JSON data and web APIs by exploring a public dataset and getting cafe recommendations from Yelp. 
End by learning some techniques to combine datasets once they have been loaded into data frames.

## Reference
https://learn.datacamp.com/courses/streamlined-data-ingestion-with-pandas

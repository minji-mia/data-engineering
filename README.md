# Data Engineering

In this track, I have discovered how to build an effective data architecture, streamline data processing, and maintain large-scale data systems. In addition to working with Python, I have also grown language skills as I work with Shell, SQL, and Scala, to create data engineering pipelines, automate common file system tasks, and build a high-performance database. Through hands-on exercises, I have added cloud and big data tools such as AWS Boto, PySpark, Spark SQL, and MongoDB, to data engineering toolkit to help create and query databases, wrangle data, and configure schedules to run your pipelines. 

- Data Engineering for Everyone [Certificate](https://github.com/minji-mia/data-engineering/blob/main/certificate/Data%20Engineering%20for%20everyone.pdf)
- Introduction to Data Engineering [Certificate](https://github.com/minji-mia/data-engineering/blob/main/certificate/Introduction%20to%20Data%20Engineering.pdf)
- Streamlined Data Ingestion with pandas

## Reference
https://learn.datacamp.com/career-tracks/data-engineer-with-python?version=3

# Data Engineering

In this track, I have discovered how to build an effective data architecture, streamline data processing, and maintain large-scale data systems. In addition to working with Python, I have also grown language skills as I work with Shell, SQL, and Scala, to create data engineering pipelines, automate common file system tasks, and build a high-performance database. Through hands-on exercises, I have added cloud and big data tools such as AWS Boto, PySpark, Spark SQL, and MongoDB, to data engineering toolkit to help create and query databases, wrangle data, and configure schedules to run your pipelines. 

- Data Engineering for Everyone [[Certificate]](https://github.com/minji-mia/data-engineering/blob/main/certificate/Data%20Engineering%20for%20everyone.pdf)
- Introduction to Data Engineering [[Certificate]](https://github.com/minji-mia/data-engineering/blob/main/certificate/Introduction%20to%20Data%20Engineering.pdf)
- Streamlined Data Ingestion with pandas [[Certificate]](https://github.com/minji-mia/data-engineering/blob/main/certificate/Streamlined%20Data%20Ingestion%20with%20pandas.pdf)
- Writing Efficient Python Code
- Writing Functions in Python
- Introduction to Shell
- Data Processing in Shell
- Introduction to Bash Scripting
- Unit Testing for Data Science in Python
- Object-Oriented Programming in Python
- Introduction to Airflow in Python
- Introduction to PySpark
- Building Data Engineering Pipelines in Python
- Introduction to AWS Boto in Python
- Introduction to Relational Databases in SQL
- Database Design
- Introduction to Scala
- Big Data Fundamentals with PySpark
- Cleaning Data with PySpark
- Introduction to Spark SQL in Python
- Cleaning Data in SQL Server Databases
- Transactions and Error Handling in SQL Server
- Building and Optimizing Triggers in SQL Server
- Improving Query Performance in SQL Server
- Introduction to MongoDB in Python
 

## Reference
https://learn.datacamp.com/career-tracks/data-engineer-with-python?version=3
